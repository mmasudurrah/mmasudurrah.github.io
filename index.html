<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Masudur Rahman </title> <meta name="author" content="Masudur Rahman"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/purdue_logo.png?e11bc2e41c3afe77db592af3eb5ad4e8"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mmasudurrah.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">Awards &amp; Grants </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching &amp; Mentoring </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">Service </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Masudur</span> Rahman </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?040f9e33eeee7f58e708c6b8399fc13e" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>PostDoc @PurdueEngineers (IE), Ph.D in CS@Purdue</p> <p>Email: rahman64@purdue.edu</p> <div class="social"> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=0nUv7b0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>¬†<a href="https://mmasudurrah.github.io/assets/pdf/CV_Md_Masudur_Rahman.pdf" title="CV" rel="external nofollow noopener" target="_blank"><i class="ai ai-cv"></i></a> </div> </div> </div> </div> <div class="clearfix"> <p>My research focuses on developing <strong>principled and adaptable intelligence</strong> for autonomous systems operating in <strong>high-stakes environments</strong> where errors carry significant cost and adaptability is essential. I aim to bridge the gap between powerful simulation-trained agents and the unpredictable demands of the real world by unifying <strong>reinforcement learning (RL)</strong> with <strong>vision-language models (VLM)</strong> to enable systems that <strong>reason, adapt, and act</strong> under uncertainty. This work advances both <strong>generalization and sample efficiency</strong> in decision-making and integrates learning with structured reasoning to produce agents capable of grounded, interactive behaviors. These contributions drive <strong>real-world impact</strong> in domains such as <strong>burn diagnosis through medical imaging</strong> and <strong>emergency robotics</strong>, where systems must perceive affordances and improvise actions in unstructured, rapidly evolving conditions.</p> <p>I am currently a <strong>Postdoctoral Research Assistant</strong> in the <em>Edwardson School of Industrial Engineering</em> at <strong>Purdue University</strong>, where I work with <strong>Dr. Juan P. Wachs</strong>. I am also a founding member of the <a href="https://engineering.purdue.edu/IE/Research/CARE" rel="external nofollow noopener" target="_blank"><strong>Center for AI and Robotic Excellence in Medicine (CARE)</strong></a> at Purdue University. I completed my <strong>Ph.D. in Computer Science</strong> from Purdue University in 2024 under the supervision of Dr. <a href="https://www.cs.purdue.edu/homes/yexiang/" rel="external nofollow noopener" target="_blank">Yexiang Xue</a>. I completed my M.S. in Computer Science at the University of Virginia in 2018. Before that, I worked as a Lecturer at BRAC University from 2013 to 2015, after earning my B.Sc. in Computer Science and Engineering from BUET in 2013.</p> <h3 id="research-highlights">RESEARCH HIGHLIGHTS</h3> <hr> <p>I work on developing intelligent systems that are both <strong>principled</strong>, meaning they are grounded in rigorous, interpretable methods, and <strong>adaptable</strong>, meaning they can generalize, reason, and improvise in dynamic, <strong>high-stakes environments</strong>. These environments are characterized by uncertainty, limited data, time-critical decision-making, and serious consequences for failure. Real-world situations such as treating trauma patients or deploying robots in disaster zones vividly illustrate these challenges, where objectives shift rapidly, information is incomplete, and decisions must be made under pressure. Ironically, <strong>these are the very contexts where we most need AI</strong>, yet current systems often fall short in delivering robust and reliable performance. Overcoming these limitations requires a new generation of intelligent systems that combine real-time decision-making with contextual understanding and principled reasoning.</p> <p>To meet these challenges, I design methods that combine <strong>reinforcement learning</strong> with <strong>foundation models</strong>, such as <strong>vision-language models</strong>, to enable agents that learn efficiently, act robustly, and generalize meaningfully beyond their training distributions. My work advances algorithms that smooth the optimization landscape to improve stability and generalization, while incorporating symbolic abstractions, procedural planning, and logic-based verification to support decision-making in ambiguous, under-specified, or novel scenarios.</p> <p>In high-stakes clinical settings (<strong>AI in Healthcare</strong>), my <strong>burn diagnosis</strong> system achieved 95% accuracy in surgical decision-making using <strong>real-patient data</strong> from a regional burn center, significantly outperforming traditional methods and clinician judgment, which typically achieve 70% accuracy. For <strong>remote robotic surgery</strong>, my teleoperation framework maintained effective control under network <strong>delays of up to five seconds</strong>, whereas conventional systems often fail beyond 300 milliseconds in <strong>emulated settings</strong>. These capabilities demonstrate strong potential for greater autonomy in low-bandwidth and resource-constrained environments.</p> <p>My research is organized into three interconnected thrusts: (1) learning <strong>generalizable and sample-efficient</strong> policies for decision-making; (2) enabling agents to <strong>reason and improvise</strong> in uncertain and data-limited settings; and (3) deploying these capabilities in <strong>embodied systems</strong> and safety-critical domains such as autonomous surgery, trauma response, and remote diagnostics. Across these directions, I aim to build AI systems that are both technically robust and structurally reliable, capable of performing with resilience, transparency, and trust in the unpredictable complexity of the real world.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Oct 13, 2025</th> <td> üìë A paper titled <em>‚ÄúAutomated Unified Reasoning with Vision-Language Models for Multi-modal Burn Assessment‚Äù</em> has been accepted for presentation at Innovative Applications of Artificial Intelligence (IAAI-26), <strong>Oral</strong>, Acceptance rate 15%. AAAI 2026. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 25, 2025</th> <td> üìë Excited to present our latest research on reinforcement learning, vision-language reasoning, and AI for healthcare at the Workshops of the Thirty-Ninth Annual Conference on Neural Information Processing Systems (<strong>NeurIPS 2025</strong>), including the Aligning Reinforcement Learning Experimentalists and Theorists (<strong>ARLET</strong>), Multimodal Algorithmic Reasoning (<strong>MAR</strong>), GenAI for Health (<strong>GenAI4Health</strong>), and Embodied World Models for Decision Making (<strong>EWM</strong>) workshops. </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 18, 2025</th> <td> üì∞ <strong>Featured in IE@Purdue News and Media</strong> ‚Äî <a href="https://engineering.purdue.edu/IE/news/2025/postdoc-best-paper" rel="external nofollow noopener" target="_blank">Best Paper Award on Burn Diagnosis</a>, <a href="https://www.linkedin.com/posts/purdueie_miua2025-activity-7363308759743426560-JfSY" rel="external nofollow noopener" target="_blank">LinkedIn</a>, <a href="https://x.com/purdue_ie/status/1957543168464834698" rel="external nofollow noopener" target="_blank">X/Twitter</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 01, 2025</th> <td> ‚ú® <strong>Awarded NSF Robust Intelligence (RI) Grant</strong> ‚Äî <em>EAGER: Theoretical Foundations for Integrating Foundational Models into Reinforcement Learning</em> (<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2521982" rel="external nofollow noopener" target="_blank">Award #2521982</a>), $300,000, 2025‚Äì2027, PI: Juan P. Wachs, serving as Key Personnel. Excited to see support for this project I‚Äôve been working on for quite a while. Grateful for the opportunity to take it further! </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 30, 2025</th> <td> üîó <strong>Affiliated with <a href="https://engineering.purdue.edu/IE/Research/CARE" rel="external nofollow noopener" target="_blank">CARE</a></strong> ‚Äî Founding member of the <a href="https://engineering.purdue.edu/IE/Research/CARE" rel="external nofollow noopener" target="_blank">Center for AI and Robotic Excellence in Medicine (CARE)</a> at Purdue University. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 17, 2025</th> <td> üèÜ Awarded <strong>Best Paper Award</strong> (Full Paper Poster Category) at <a href="https://conferences.leeds.ac.uk/miua/" rel="external nofollow noopener" target="_blank">MIUA 2025</a> for the paper titled: Knowledge-Driven Hypothesis Generation for Burn Diagnosis from Ultrasound with Vision- Language Model. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 15, 2025</th> <td> Attending <a href="https://conferences.leeds.ac.uk/miua/" rel="external nofollow noopener" target="_blank">MIUA 2025</a> at the University of Leeds, UK. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 24, 2025</th> <td> üìë A paper got accepted to the <a href="https://medinform.jmir.org/" rel="external nofollow noopener" target="_blank">JMIR Medical Informatics</a> 2025. Paper title: AI-Driven Integrated System for Burn Depth Prediction With Electronic Medical Records: Algorithm Development and Validation. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 23, 2025</th> <td> ‚ú® Awarded a <strong>grant</strong> through the <strong>Health of the Forces Pilot Funding Program (Purdue University)</strong> for our project <em>‚ÄúAccelerated Expertise: AI-Powered Diagnostic Pathways for Rapid Clinical Mastery of Burns,‚Äù</em> in collaboration with Dr. Juan Wachs (Industrial Engineering) and Dr. Aniket Bera (Computer Science). This project aims to enhance acute care and long-term outcomes for burn-injured service members using AI-powered diagnostic tools. Excited to continue working at the intersection of AI and burn care! </td> </tr> <tr> <th scope="row" style="width: 20%">May 25, 2025</th> <td> üìë An abstract paper has been accepted to the <a href="https://www.plasticsurgerythemeeting.com/" rel="external nofollow noopener" target="_blank">Plastic Surgery The Meeting (PSTM)</a> 2025.<br> The work will be presented at PSTM 2025 ‚Äî the premier annual conference organized by the American Society of Plastic Surgeons (ASPS)‚Äî at the New Orleans, Louisiana, in October 2025. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AAAI-2026</abbr> </div> <div id="rahman2026automated" class="col-sm-8"> <div class="title">Automated Unified Reasoning with Vision-Language Models for Multi-modal Burn Assessment</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Mohamed El Masry,¬†Gayle Gordillo,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>In Proceedings of the AAAI Conference on Artificial Intelligence (IAAI)</em> , 2026 </div> <div class="periodical"> Oral, Innovative Applications of Artificial Intelligence (IAAI-26), Acceptance rate: 15% </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2026automated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automated Unified Reasoning with Vision-Language Models for Multi-modal Burn Assessment}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Masry, Mohamed El and Gordillo, Gayle and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence (IAAI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Oral, Innovative Applications of Artificial Intelligence (IAAI-26), Acceptance rate: 15%}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS Workshop</abbr> </div> <div id="rahman2025robust" class="col-sm-8"> <div class="title">Robust Policy Gradient Optimization through Action Parameter Perturbation in Reinforcement Learning</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Juan P. Wachs,¬†and¬†Yexiang Xue </div> <div class="periodical"> <em>In Proceedings of the Aligning Reinforcement Learning Experimentalists and Theorists Workshop (ARLET@NeurIPS 2025) at the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</em> , 2025 </div> <div class="periodical"> Peer-reviewed, non-archival workshop paper </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2025robust</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robust Policy Gradient Optimization through Action Parameter Perturbation in Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Wachs, Juan P. and Xue, Yexiang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Aligning Reinforcement Learning Experimentalists and Theorists Workshop (ARLET@NeurIPS 2025) at the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Peer-reviewed, non-archival workshop paper}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS Workshop</abbr> </div> <div id="rahman2025intent" class="col-sm-8"> <div class="title">Intent-Based Reward Inference for Value-Aligned Reinforcement Learning</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>In Proceedings of the Aligning Reinforcement Learning Experimentalists and Theorists Workshop (ARLET@NeurIPS 2025) at the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</em> , 2025 </div> <div class="periodical"> Peer-reviewed, non-archival workshop paper </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2025intent</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Intent-Based Reward Inference for Value-Aligned Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Aligning Reinforcement Learning Experimentalists and Theorists Workshop (ARLET@NeurIPS 2025) at the Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Peer-reviewed, non-archival workshop paper}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS Workshop</abbr> </div> <div id="rahman2025improvisational" class="col-sm-8"> <div class="title">Improvisational Reasoning with Vision-Language Models for Grounded Procedural Planning</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Yupeng Zhuo,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>In Proceedings of the Thirty-Ninth Annual Conference on Neural Information Processing Systems Workshops (NeurIPS 2025): Multimodal Algorithmic Reasoning Workshop (MAR@NeurIPS 2025), GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health@NeurIPS 2025), Embodied World Models for Decision Making (EWM@NeurIPS 2025)</em> , 2025 </div> <div class="periodical"> Peer-reviewed, non-archival workshop paper </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2025improvisational</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improvisational Reasoning with Vision-Language Models for Grounded Procedural Planning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Zhuo, Yupeng and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Thirty-Ninth Annual Conference on Neural Information Processing Systems Workshops (NeurIPS 2025): 
                    Multimodal Algorithmic Reasoning Workshop (MAR@NeurIPS 2025), 
                    GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health@NeurIPS 2025), 
                    Embodied World Models for Decision Making (EWM@NeurIPS 2025)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Peer-reviewed, non-archival workshop paper}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS Workshop</abbr> </div> <div id="rahman2025burn" class="col-sm-8"> <div class="title">Vision-Language Reasoning for Burn Depth Assessment with Structured Diagnostic Hypotheses</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Mohamed El Masry,¬†Kristo Nuutila,¬†Gayle Gordillo,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>In Proceedings of the Thirty-Ninth Annual Conference on Neural Information Processing Systems Workshops (NeurIPS 2025): GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health@NeurIPS 2025), Embodied World Models for Decision Making (EWM@NeurIPS 2025)</em> , 2025 </div> <div class="periodical"> Peer-reviewed, non-archival workshop paper </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2025burn</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Vision-Language Reasoning for Burn Depth Assessment with Structured Diagnostic Hypotheses}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and El Masry, Mohamed and Nuutila, Kristo and Gordillo, Gayle and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Thirty-Ninth Annual Conference on Neural Information Processing Systems Workshops (NeurIPS 2025): 
                    GenAI for Health: Potential, Trust, and Policy Compliance (GenAI4Health@NeurIPS 2025), 
                    Embodied World Models for Decision Making (EWM@NeurIPS 2025)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Peer-reviewed, non-archival workshop paper}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/burnaid_toc-480.webp 480w,/assets/img/publication_preview/burnaid_toc-800.webp 800w,/assets/img/publication_preview/burnaid_toc-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/burnaid_toc.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="burnaid_toc.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2025burnaid" class="col-sm-8"> <div class="title">AI-Driven Integrated System for Burn Depth Prediction With Electronic Medical Records: Algorithm Development and Validation</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Mohamed El Masry,¬†Surya Gnyawali,¬†Yexiang Xue,¬†Gayle Gordillo,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>JMIR Medical Informatics</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">rahman2025burnaid</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Masry, Mohamed El and Gnyawali, Surya and Xue, Yexiang and Gordillo, Gayle and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AI-Driven Integrated System for Burn Depth Prediction With Electronic Medical Records: Algorithm Development and Validation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{JMIR Medical Informatics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.2196/68366}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MIUA</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/burn_ultrasound_ambush_miua2025-480.webp 480w,/assets/img/publication_preview/burn_ultrasound_ambush_miua2025-800.webp 800w,/assets/img/publication_preview/burn_ultrasound_ambush_miua2025-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/burn_ultrasound_ambush_miua2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="burn_ultrasound_ambush_miua2025.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2025knowledge" class="col-sm-8"> <div class="title">Knowledge-Driven Hypothesis Generation for Burn Diagnosis from Ultrasound with Vision- Language Model</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Mohamed El Masry,¬†Gayle Gordillo,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>In Annual Conference on Medical Image Understanding and Analysis</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Best Paper</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/koder_ultrasound_burn_miua2025.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Received the Best Paper Award in the Full Paper Poster category at the Medical Image Understanding and Analysis (MIUA) 2025, held in Leeds, UK.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2025knowledge</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Knowledge-Driven Hypothesis Generation for Burn Diagnosis from Ultrasound with Vision-
  Language Model}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Masry, Mohamed El and Gordillo, Gayle and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Annual Conference on Medical Image Understanding and Analysis}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MHSRS-Abstract</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mhsrs_2025_sample_cot-480.webp 480w,/assets/img/publication_preview/mhsrs_2025_sample_cot-800.webp 800w,/assets/img/publication_preview/mhsrs_2025_sample_cot-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mhsrs_2025_sample_cot.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mhsrs_2025_sample_cot.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2025cot" class="col-sm-8"> <div class="title">A Chain-of-Thought AI Reasoning Framework for Burn Diagnosis</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†Mohamed El Masry,¬†Gayle Gordillo,¬†and¬†Juan P. Wachs </div> <div class="periodical"> <em>In Military Health System Research Symposium</em> , 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2025cot</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Chain-of-Thought AI Reasoning Framework for Burn Diagnosis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Masry, Mohamed El and Gordillo, Gayle and Wachs, Juan P.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Military Health System Research Symposium}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NAACL</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/language_state-480.webp 480w,/assets/img/publication_preview/language_state-800.webp 800w,/assets/img/publication_preview/language_state-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/language_state.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="language_state.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2024natural" class="col-sm-8"> <div class="title">Natural Language-based State Representation in Deep Reinforcement Learning</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†and¬†Yexiang Xue </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: NAACL 2024</em> Appears in NeurIPS 2023 Foundation Models for Decision Making Workshop (FMDM) Workshop , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://aclanthology.org/2024.findings-naacl.83.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2024natural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Natural Language-based State Representation in Deep Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Xue, Yexiang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: NAACL 2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1310--1319}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECML-PKDD</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/thinker_overview-480.webp 480w,/assets/img/publication_preview/thinker_overview-800.webp 800w,/assets/img/publication_preview/thinker_overview-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/thinker_overview.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="thinker_overview.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2022bootstrap" class="col-sm-8"> <div class="title">Bootstrap State Representation using Style Transfer for Better Generalization in Deep Reinforcement Learning</div> <div class="author"> <em>Md Masudur Rahman</em>,¬†and¬†Yexiang Xue </div> <div class="periodical"> <em>In European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2207.07749.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2022bootstrap</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bootstrap State Representation using Style Transfer for Better Generalization in Deep Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman, Md Masudur and Xue, Yexiang}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/chapter/10.1007/978-3-031-26412-2_7}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICRA</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/icra2021_forward_framework-480.webp 480w,/assets/img/publication_preview/icra2021_forward_framework-800.webp 800w,/assets/img/publication_preview/icra2021_forward_framework-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/icra2021_forward_framework.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="icra2021_forward_framework.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gonzalez2021deserts" class="col-sm-8"> <div class="title">Deserts: Delay-tolerant semi-autonomous robot teleoperation for surgery</div> <div class="author"> Glebys Gonzalez,¬†Mridul Agarwal,¬†Mythra V Balakuntala,¬†<em>Md Masudur Rahman</em>,¬†Upinder Kaur,¬†Richard M Voyles,¬†Vaneet Aggarwal,¬†Yexiang Xue,¬†and¬†Juan Wachs </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ICRA2021-DESERTS.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">gonzalez2021deserts</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deserts: Delay-tolerant semi-autonomous robot teleoperation for surgery}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gonzalez, Glebys and Agarwal, Mridul and Balakuntala, Mythra V and Rahman, Md Masudur and Kaur, Upinder and Voyles, Richard M and Aggarwal, Vaneet and Xue, Yexiang and Wachs, Juan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Robotics and Automation (ICRA)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Biomedical Journal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/sartres_framework-480.webp 480w,/assets/img/publication_preview/sartres_framework-800.webp 800w,/assets/img/publication_preview/sartres_framework-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/sartres_framework.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sartres_framework.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2021sartres" class="col-sm-8"> <div class="title">SARTRES: A semi-autonomous robot teleoperation environment for surgery</div> <div class="author"> <em>Md Masudur Rahman*</em>,¬†Mythra V Balakuntala*,¬†Glebys Gonzalez,¬†Mridul Agarwal,¬†Upinder Kaur,¬†Vishnunandan LN Venkatesh,¬†Natalia Sanchez-Tamayo,¬†Yexiang Xue,¬†Richard M Voyles,¬†Vaneet Aggarwal,¬†and¬†Juan Wachs </div> <div class="periodical"> <em>Computer Methods in Biomechanics and Biomedical Engineering: Imaging &amp; Visualization</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/SARTRES-AECAI-TCIV-2020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">rahman2021sartres</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SARTRES: A semi-autonomous robot teleoperation environment for surgery}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman*, Md Masudur and Balakuntala*, Mythra V and Gonzalez, Glebys and Agarwal, Mridul and Kaur, Upinder and Venkatesh, Vishnunandan LN and Sanchez-Tamayo, Natalia and Xue, Yexiang and Voyles, Richard M and Aggarwal, Vaneet and Wachs, Juan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computer Methods in Biomechanics and Biomedical Engineering: Imaging \&amp; Visualization}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{376--383}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Taylor \&amp; Francis}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IROS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/desk_dataset-480.webp 480w,/assets/img/publication_preview/desk_dataset-800.webp 800w,/assets/img/publication_preview/desk_dataset-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/desk_dataset.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="desk_dataset.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="madapana2019desk" class="col-sm-8"> <div class="title">Desk: A robotic activity dataset for dexterous surgical skills transfer to medical robots</div> <div class="author"> Naveen Madapana*,¬†<em>Md Masudur Rahman*</em>,¬†Natalia Sanchez-Tamayo*,¬†Mythra V Balakuntala,¬†Glebys Gonzalez,¬†Jyothsna Padmakumar Bindu,¬†LN Vishnunandan Venkatesh,¬†Xingguang Zhang,¬†Juan Barragan Noguera,¬†Thomas Low,¬†and¬† others </div> <div class="periodical"> <em>In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/DESK-IROS-2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">madapana2019desk</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Desk: A robotic activity dataset for dexterous surgical skills transfer to medical robots}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Madapana*, Naveen and Rahman*, Md Masudur and Sanchez-Tamayo*, Natalia and Balakuntala, Mythra V and Gonzalez, Glebys and Bindu, Jyothsna Padmakumar and Venkatesh, LN Vishnunandan and Zhang, Xingguang and Noguera, Juan Barragan and Low, Thomas and others}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">RO-MAN</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/roman2019_transfer_architecture-480.webp 480w,/assets/img/publication_preview/roman2019_transfer_architecture-800.webp 800w,/assets/img/publication_preview/roman2019_transfer_architecture-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/roman2019_transfer_architecture.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="roman2019_transfer_architecture.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="rahman2019transferring" class="col-sm-8"> <div class="title">Transferring Dexterous Surgical Skill Knowledge between Robots for Semi-autonomous Teleoperation</div> <div class="author"> <em>Md Masudur Rahman*</em>,¬†Natalia Sanchez-Tamayo*,¬†Glebys Gonzalez,¬†Mridul Agarwal,¬†Vaneet Aggarwal,¬†Richard M Voyles,¬†Yexiang Xue,¬†and¬†Juan Wachs </div> <div class="periodical"> <em>In 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ROMAN-2019-Transfer-Learning.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rahman2019transferring</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Transferring Dexterous Surgical Skill Knowledge between Robots for Semi-autonomous Teleoperation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rahman*, Md Masudur and Sanchez-Tamayo*, Natalia and Gonzalez, Glebys and Agarwal, Mridul and Aggarwal, Vaneet and Voyles, Richard M and Xue, Yexiang and Wachs, Juan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%72%61%68%6D%61%6E%36%34@%70%75%72%64%75%65.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0002-3633-0621" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=0nUv7b0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/50743443" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/masud99r" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/masud99r" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/masud99r" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">The best way to reach me is via email. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Masudur Rahman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-T4WV8EF43W"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-T4WV8EF43W");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>