<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Research | Masudur Rahman </title> <meta name="author" content="Masudur Rahman"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/purdue_logo.png?e11bc2e41c3afe77db592af3eb5ad4e8"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mmasudurrah.github.io/projects/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Masudur</span> Rahman </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">Awards &amp; Grants </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching &amp; Mentoring </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">Service </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Research</h1> <p class="post-description"></p> </header> <article> <h3 id="research-vision">Research Vision</h3> <p>Most artificial intelligence systems are designed and evaluated under static assumptions: fixed data distributions, stable environments, and well-specified objectives. In real-world deployment, these assumptions rarely hold. Environments change, objectives are ambiguous, and constraints emerge only after systems are in use. In high-stakes settings, such failures are not merely inconvenient—they can lead to unsafe or irreversible outcomes.</p> <p>My research centers on <strong>adaptive intelligence</strong>: the ability of learning systems to maintain meaningful, reliable behavior when environments, objectives, or constraints change. I study adaptation as a systems-level property rather than a training-time performance metric, with an emphasis on principled reinforcement learning grounded in real-world failure modes, often informed by close interaction with domain experts and collaborators.</p> <hr> <h3 id="research-themes">Research Themes</h3> <h4 id="1-learning-and-generalization-under-change">1. Learning and Generalization Under Change</h4> <p>Reinforcement learning provides a natural framework for adaptive decision-making, but standard RL methods often fail to generalize when assumptions about stationarity, reward fidelity, or representation break. A central theme of my work is understanding <strong>why generalization collapses under non-stationarity</strong>, even when policies perform well during training.</p> <p>I study structural causes of failure in learning systems, including instability in representations, sensitivity of optimization dynamics, and reward drift under environmental change. My work develops principled methods that improve stability and transfer by treating generalization as a property of the learning problem itself, rather than as a consequence of policy capacity or data scale.</p> <p>This line of research contributes algorithmic insights and diagnostic tools for reinforcement learning systems deployed beyond controlled benchmarks.</p> <hr> <h4 id="2-semantic-representations-and-reward-as-inferred-intent">2. Semantic Representations and Reward as Inferred Intent</h4> <p>In many real-world settings, objectives are inherently underspecified. Reward functions act as proxies for intent, but these proxies often degrade as context evolves. My research treats <strong>reward and representation as interfaces that must remain meaningful under change</strong>, rather than as fixed ground truth.</p> <p>I explore semantic state representations—including language and vision-language abstractions—that preserve task-relevant meaning across environments while abstracting away low-level variability. In parallel, I study reward modeling as a problem of <strong>intent inference</strong>, where systems must reason about goals and constraints rather than optimize brittle scalar signals.</p> <p>This perspective reframes reward design as a central object of study and provides a foundation for more reliable adaptation in dynamic, high-stakes environments.</p> <hr> <h4 id="3-reasoning-under-ambiguity-and-limited-data">3. Reasoning Under Ambiguity and Limited Data</h4> <p>In high-stakes domains such as healthcare, learning systems must operate under limited data, partial observability, and ambiguous supervision. In these settings, unconstrained optimization is often unacceptable.</p> <p>My work integrates structured reasoning with learning to constrain adaptation under uncertainty. I develop systems that generate and verify hypotheses, incorporate domain constraints, and provide interpretable decision processes. These approaches allow learning systems to act reliably even when feedback is sparse or objectives are ill-defined.</p> <p>In medical decision-making applications, this integration of reasoning and perception has enabled accurate, interpretable systems validated in real clinical contexts.</p> <hr> <h4 id="4-embodied-adaptive-systems-as-a-reality-check">4. Embodied Adaptive Systems as a Reality Check</h4> <p>Simulation and benchmark environments often hide the consequences of broken assumptions. Embodied systems do not. Physical interaction introduces non-stationary dynamics, sensing noise, delays, and irreversible outcomes that expose brittle learning assumptions immediately.</p> <p>My research in embodied robotics—particularly in shared autonomy and teleoperation—uses physical deployment as a <strong>truth test</strong> for adaptive intelligence. I develop semantic action abstractions, delay-tolerant control frameworks, and real-world datasets to evaluate which learning and reasoning methods survive deployment.</p> <p>This work grounds theoretical and algorithmic insights in reality and feeds back into the design of more robust adaptive systems.</p> <hr> <h3 id="integration-and-future-directions">Integration and Future Directions</h3> <p>Together, these research directions form a unified program that integrates learning, reasoning, and embodiment to study adaptive intelligence in high-stakes environments. This work naturally benefits from interdisciplinary interaction, and I am interested in continuing to engage with collaborators across machine learning, robotics, and applied domains where real-world constraints shape intelligent behavior.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Masudur Rahman. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?06cae41083477f121be8cd9797ad8e2f"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-T4WV8EF43W"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-T4WV8EF43W");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>